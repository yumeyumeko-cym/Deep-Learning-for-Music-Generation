{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1700 songs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing songs: 100%|██████████| 1700/1700 [00:34<00:00, 49.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 362402 sequences.\n",
      "<class 'MusicDataset.MusicDataset'>\n"
     ]
    }
   ],
   "source": [
    "import music21 as m21\n",
    "import numpy as np\n",
    "import os\n",
    "from music21 import *\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from MusicDataset import MusicDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "env = environment.Environment()\n",
    "env['musicxmlPath'] = r'D:/MuseScore 4/bin/MuseScore4.exe'\n",
    "env['musescoreDirectPNGPath'] = r'D:/MuseScore 4/bin/MuseScore4.exe'\n",
    "\n",
    "\n",
    "DATASET_PATH = \"deutschl/erk\"\n",
    "ACCEPTABLE_DURATIONS = [\n",
    "    0.25, # 16th note\n",
    "    0.5, # 8th note\n",
    "    0.75,\n",
    "    1.0, # quarter note\n",
    "    1.5,\n",
    "    2, # half note\n",
    "    3,\n",
    "    4 # whole note\n",
    "]\n",
    "\n",
    "SAVE_DIR = \"./saved_preprocessed\"\n",
    "SEQUENCE_LENGTH = 64\n",
    "TRAINING_DATASET_FILE_PATH = \"training_dataset.txt\"\n",
    "MAPPING_FILE_PATH = \"mapping.json\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_songs_in_kern(dataset_path):\n",
    "    \"\"\"\n",
    "    Loads dataset using m21.\n",
    "\n",
    "    :param dataset_path (str): Path to dataset\n",
    "    :return (List) <class 'music21.stream.base.Score'>\n",
    "    \"\"\"\n",
    "    songs = []\n",
    "\n",
    "    for path, subdirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "\n",
    "            # Consider only MIDI files\n",
    "            if file.lower().endswith(\".krn\"):\n",
    "                song = m21.converter.parse(os.path.join(path, file))\n",
    "                songs.append(song)\n",
    "    return songs\n",
    "\n",
    "\n",
    "def valid_durations(song, acceptable_durations):\n",
    "    \"\"\"\n",
    "    Check if all notes and rests have acceptable durations.\n",
    "\n",
    "    :param song (m21 stream)\n",
    "    :param acceptable_durations (list): List of acceptable duration in quarter length\n",
    "    :return (bool):\n",
    "    \"\"\"\n",
    "    \n",
    "    return all(note.duration.quarterLength in acceptable_durations for note in song.flatten().notesAndRests)\n",
    "\n",
    "\"\"\"\n",
    "Music Transpose\n",
    "In the context of deep learning for music generation, the ability to transpose music is valuable for several reasons, reflecting both the enhancement of the dataset used for training deep learning models and the adaptation of generated music to specific musical contexts or preferences. Here are key reasons why a transpose function is important:\n",
    "\n",
    "1. Data Augmentation\n",
    "Diversity in Training Data: Transposing existing pieces into different keys increases the diversity of the training dataset without needing to collect new compositions. This diversity helps in training more robust and versatile models capable of understanding and generating music in various keys.\n",
    "Improved Generalization: By presenting the model with the same piece in multiple keys, it can learn to recognize and generate the underlying patterns of music theory that are invariant to key changes. This improves the model's ability to generalize from its training data to new compositions.\n",
    "2. Key Normalization\n",
    "Consistent Key for Model Training: Training models on data that is normalized to a specific key (often C major/A minor for simplicity) can simplify the learning process. It reduces the complexity of the input space, potentially making it easier for the model to learn the structure and progression of musical pieces.\n",
    "Easier Pattern Recognition: Models might find it easier to recognize patterns and structures in music when the variability due to different keys is removed. This can lead to more efficient learning and a stronger focus on other musical aspects like rhythm, dynamics, and melody.\n",
    "3. Adaptation to Instrumentation or Vocal Ranges\n",
    "Matching Musical Range: Once music is generated, it might need to be adapted to fit the specific range of an instrument or the vocal range of a singer. Transposing the generated piece to a key that suits the intended performers can make the music more practical and enjoyable to play or sing.\n",
    "\"\"\"\n",
    "\n",
    "def transpose_to_Cmaj_Amin(song):\n",
    "    \"\"\"\n",
    "    Transposes a song to C major or A minor.\n",
    "\n",
    "    :param song (m21 stream)\n",
    "    :return transposed song (m21 stream)\n",
    "    \"\"\"\n",
    "    # Analyze the key of the song\n",
    "    original_key = song.analyze('key')\n",
    "    \n",
    "    # Determine the target key based on the mode of the original key\n",
    "    target_key = key.Key('C') if original_key.mode == 'major' else key.Key('A', 'minor')\n",
    "    \n",
    "    # Calculate the interval between the original key's tonic and the target key's tonic\n",
    "    transposition_interval = interval.Interval(original_key.tonic, target_key.tonic)\n",
    "    \n",
    "    # Transpose the song by the calculated interval\n",
    "    transposed_song = song.transpose(transposition_interval)\n",
    "    \n",
    "    return transposed_song\n",
    "\n",
    "def encode(song, time_step=0.25):\n",
    "    \"\"\"\n",
    "    p=60, d=1.0 -> 60, _, _, _\n",
    "\n",
    "    interger for notes, 'r' for representing a rest, and '_' for representing notes/rests that are carried over into a new time step.\n",
    "\n",
    "    :param song (m21 stream)\n",
    "    :param time_step (float): Duration of each time step in quarter length\n",
    "    :return encoded song (str)\n",
    "    \"\"\"            \n",
    "\n",
    "    encoded_sequence = []\n",
    "\n",
    "    for elem in song.flatten().notesAndRests:\n",
    "        if isinstance(elem, note.Note):\n",
    "            symbol = elem.pitch.midi\n",
    "\n",
    "        elif isinstance(elem, note.Rest):\n",
    "            symbol = \"r\"\n",
    "        \n",
    "\n",
    "        steps = int(elem.duration.quarterLength / time_step)\n",
    "        \n",
    "        for step_index in range(steps):\n",
    "            if step_index == 0:\n",
    "                # Encode the symbol directly for the first step\n",
    "                encoded_sequence.append(symbol)\n",
    "            else:\n",
    "                # Use '_' to indicate continuation for subsequent steps\n",
    "                encoded_sequence.append('_')\n",
    "\n",
    "    # Convert the list of encoded elements into a single string for output\n",
    "    encoded_string = \" \".join(str(item) for item in encoded_sequence)\n",
    "\n",
    "\n",
    "    return encoded_string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(dataset_path):\n",
    "    songs = load_songs_in_kern(dataset_path)\n",
    "    print(f\"Loaded {len(songs)} songs.\")\n",
    "    \n",
    "    for i, song in tqdm(enumerate(songs), total=len(songs), desc=\"Processing songs\"):\n",
    "        if not valid_durations(song, ACCEPTABLE_DURATIONS):\n",
    "            continue\n",
    "\n",
    "        # transpose song to Cmaj/Amin\n",
    "        song = transpose_to_Cmaj_Amin(song)\n",
    "\n",
    "        # encode song\n",
    "        song_encoded = encode(song)\n",
    "\n",
    "        # Ensure the 'preprocessed' directory exists\n",
    "        preprocessed_file = os.path.join(SAVE_DIR, str(i))\n",
    "        \n",
    "        # Save songs to text file\n",
    "        with open(preprocessed_file, \"w\") as fp:  # Ensure encoding is set for special characters\n",
    "            fp.write(song_encoded)\n",
    "\n",
    "            \n",
    "    return preprocessed_file\n",
    "\n",
    "\n",
    "def load(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_contents = file.read()\n",
    "    return file_contents\n",
    "\n",
    "\n",
    "def collating(dataset_path, file_dataset_path, sequence_length):\n",
    "    \"\"\"\n",
    "    Generates a file collating all the encoded songs and adding new piece delimiters.\n",
    "    \n",
    "    :param dataset_path: Path to folder containing the encoded songs.\n",
    "    :param file_dataset_path: Path to file for saving songs in a single file.\n",
    "    :param sequence_length (int): number of delimiters used to separate songs\n",
    "    :return <class 'str'> encoded songs with delimiters\n",
    "    \"\"\"\n",
    "    new_song_delimiter = \"/ \" * sequence_length\n",
    "    songs = \"\"\n",
    "\n",
    "    # load encoded songs and add delimiters\n",
    "    for path, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(path, file)\n",
    "            song = load(file_path)\n",
    "            songs = songs + song + \" \" + new_song_delimiter\n",
    "\n",
    "    # remove empty space from last character of string\n",
    "    songs = songs[:-1]\n",
    "\n",
    "    # save string that contains all the dataset\n",
    "    with open(file_dataset_path, \"w\") as fp:\n",
    "        fp.write(songs)\n",
    "\n",
    "    return songs\n",
    "    \n",
    "\n",
    "\n",
    "def map_json(songs, file_mapping_path):\n",
    "    \"\"\"\n",
    "    Generate a mapping from each unique symbol in the encoded songs to an integer.\n",
    "    \n",
    "    :param songs: String containing all encoded songs with delimiters.\n",
    "    :param file_mapping_path: Path to file for saving the mapping as JSON.\n",
    "    \"\"\"\n",
    "    # Split the songs string into a list of symbols\n",
    "    #songs = load(file_dataset_path)\n",
    "    #print(songs)\n",
    "    #print('\\n')\n",
    "    symbols = songs.split(\" \")\n",
    "    #print(symbols)\n",
    "    # Remove empty symbols caused by consecutive spaces\n",
    "    symbols = [symbol for symbol in symbols if symbol != \"\"]\n",
    "    \n",
    "    # Use a set to find unique symbols\n",
    "    unique_symbols = set(symbols)\n",
    "    # print(unique_symbols)\n",
    "    # for symbol in enumerate(unique_symbols):\n",
    "    #     print(symbol)\n",
    "    # Create a mapping from symbols to integers\n",
    "    symbol_to_int = {symbol: i for i, symbol in enumerate(unique_symbols)}\n",
    "    \n",
    "    # Save the mapping to a JSON file\n",
    "    with open(file_mapping_path, \"w\") as f:\n",
    "        json.dump(symbol_to_int, f, indent=4)\n",
    "\n",
    "    return symbol_to_int\n",
    "\n",
    "def mapped_songs(file_mapping_path, songs):\n",
    "    \"\"\"\n",
    "    Generate mapped songs for training\n",
    "\n",
    "    :param file_mapping_path: Path to file containing the mapping as JSON.\n",
    "    :param songs: String containing all encoded songs with delimiters.\n",
    "    :return: List of mapped songs\n",
    "    \"\"\"\n",
    "    mapped_songs = []\n",
    "    # Load the mapping from JSON\n",
    "    with open(file_mapping_path, \"r\") as f:\n",
    "        mapping = json.load(f)\n",
    "\n",
    "    # Split the songs string into a list of symbols\n",
    "    songs = songs.split(\" \")\n",
    "    for symbol in songs:\n",
    "        # Map each symbol to an integer\n",
    "        mapped_songs.append(mapping[symbol])\n",
    "\n",
    "    return mapped_songs\n",
    "\n",
    "def generate_training_sequences_pytorch(sequence_length):\n",
    "    \"\"\"Create input and output data samples for training in PyTorch. Each sample is a sequence.\n",
    "\n",
    "    :param sequence_length (int): Length of each sequence. With a quantisation at 16th notes, 64 notes equates to 4 bars\n",
    "\n",
    "    :return inputs (Tensor): Training inputs\n",
    "    :return targets (Tensor): Training targets\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    songs = load(TRAINING_DATASET_FILE_PATH)\n",
    "    int_songs = mapped_songs(MAPPING_FILE_PATH, songs)\n",
    "\n",
    "\n",
    "    # Generate the training sequences\n",
    "    num_sequences = len(int_songs) - sequence_length\n",
    "    for i in range(num_sequences):\n",
    "        inputs.append(int_songs[i:i+sequence_length])\n",
    "        targets.append(int_songs[i+sequence_length])\n",
    "\n",
    "    vocabulary_size = len(set(int_songs))\n",
    "\n",
    "    # Convert inputs to one-hot encoded tensors\n",
    "    inputs_one_hot = torch.zeros(len(inputs), sequence_length, vocabulary_size)\n",
    "    for i, sequence in enumerate(inputs):\n",
    "        for j, index in enumerate(sequence):\n",
    "            inputs_one_hot[i, j, index] = 1.0\n",
    "\n",
    "    targets = torch.tensor(targets)\n",
    "\n",
    "    \n",
    "\n",
    "    return inputs_one_hot, targets\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preprocess(DATASET_PATH)\n",
    "songs = collating(SAVE_DIR, TRAINING_DATASET_FILE_PATH, SEQUENCE_LENGTH)\n",
    "map_json(songs, MAPPING_FILE_PATH)\n",
    "dataset = generate_training_sequences_pytorch(SEQUENCE_LENGTH)\n",
    "print(type(dataset))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
